{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcffcfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\IIT BBS\\Job Resources\\Business Optima\\new-pdf-agent\n"
     ]
    }
   ],
   "source": [
    "# --- 0) bootstrap ---\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT / \"pyproject.toml\").exists() and ROOT != ROOT.parent:\n",
    "    ROOT = ROOT.parent\n",
    "os.chdir(ROOT)\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(\"Project root:\", ROOT)\n",
    "\n",
    "DOC_ID = os.environ.get(\"PDF_AGENT_DOC_ID\", \"NFS_2019\")   # override via env if needed\n",
    "ARTIFACTS_ROOT = Path(\"data/artifacts\")\n",
    "MODELS_ROOT    = Path(\"data/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eace770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guardrails': {'blocked_regex': ['(?i)hack|exploit|payload'],\n",
      "                'max_input_chars': 4000,\n",
      "                'model_role': 'intro',\n",
      "                'pii_block': False,\n",
      "                'pii_regex': ['[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,}',\n",
      "                              '\\\\b(?:\\\\+?\\\\d{1,3}[-.\\\\s]?)?(?:\\\\(?\\\\d{3}\\\\)?[-.\\\\s]?)?\\\\d{3}[-.\\\\s]?\\\\d{4}\\\\b'],\n",
      "                'prompt_path': 'configs/prompts/chat/intro_guard.txt'},\n",
      " 'models': {'intro': {'base_url': 'http://127.0.0.1:11434',\n",
      "                      'max_new_tokens': 256,\n",
      "                      'model': 'llama3.2:latest',\n",
      "                      'provider': 'ollama',\n",
      "                      'temperature': 0.2},\n",
      "            'output': {'base_url': 'http://127.0.0.1:11434',\n",
      "                       'max_new_tokens': 512,\n",
      "                       'model': 'llama3.2:latest',\n",
      "                       'provider': 'ollama',\n",
      "                       'temperature': 0.3},\n",
      "            'splitter': {'base_url': 'http://127.0.0.1:11434',\n",
      "                         'max_new_tokens': 256,\n",
      "                         'model': 'llama3.2:latest',\n",
      "                         'provider': 'ollama',\n",
      "                         'temperature': 0.2}},\n",
      " 'splitter': {'allow_notes': True,\n",
      "              'max_questions': 6,\n",
      "              'prompt_path': 'configs/prompts/chat/splitter.txt'},\n",
      " 'structured_output': {'method': 'json_schema', 'prefer_native': True}}\n"
     ]
    }
   ],
   "source": [
    "from packages.core_config.config import load_yaml\n",
    "import pprint, yaml\n",
    "\n",
    "cfg = load_yaml(\"configs/providers.yaml\")\n",
    "snap = {\n",
    "    \"structured_output\": cfg.get(\"chat.structured_output\", {}),\n",
    "    \"splitter\": cfg.get(\"chat.splitter\", {}),\n",
    "    \"guardrails\": cfg.get(\"chat.guardrails\", {}),\n",
    "    \"models\": {\n",
    "        \"intro\": cfg.get(\"chat.models.intro\", {}),\n",
    "        \"splitter\": cfg.get(\"chat.models.splitter\", {}),\n",
    "        \"output\": cfg.get(\"chat.models.output\", {}),\n",
    "    }\n",
    "}\n",
    "pprint.pprint(snap)\n",
    "\n",
    "# Convenience vars\n",
    "SO_PREFER = bool(cfg.get(\"chat.structured_output.prefer_native\", True))\n",
    "SO_METHOD = str(cfg.get(\"chat.structured_output.method\", \"json_schema\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba5ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro     http://127.0.0.1:11434 -> 200\n",
      "splitter  http://127.0.0.1:11434 -> 200\n",
      "output    http://127.0.0.1:11434 -> 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def check_roles_health(yaml_path=\"configs/providers.yaml\", roles=(\"intro\",\"splitter\",\"output\")):\n",
    "    cfg = yaml.safe_load(open(yaml_path, \"r\", encoding=\"utf-8\"))\n",
    "    failed = []\n",
    "    for role in roles:\n",
    "        url = cfg[\"chat\"][\"models\"][role][\"base_url\"]\n",
    "        try:\n",
    "            r = requests.get(f\"{url}/api/tags\", timeout=10)\n",
    "            print(f\"{role:9s} {url} -> {r.status_code}\")\n",
    "            if r.status_code != 200:\n",
    "                failed.append((role, url, f\"HTTP {r.status_code}\"))\n",
    "        except Exception as e:\n",
    "            print(f\"{role:9s} {url} -> ERROR: {type(e).__name__}: {e}\")\n",
    "            failed.append((role, url, str(e)))\n",
    "    return failed\n",
    "\n",
    "fails = check_roles_health()\n",
    "if fails:\n",
    "    raise SystemExit(\n",
    "        \"Ollama health check failed for roles:\\n\" +\n",
    "        \"\\n\".join(f\" - {role} at {url}: {err}\" for role, url, err in fails) +\n",
    "        \"\\n\\nQuick fixes:\\n\"\n",
    "        \"  1) Ensure `ollama serve` is running on that port\\n\"\n",
    "        \"  2) Make YAML base_url match the running port (e.g., http://127.0.0.1:11434)\\n\"\n",
    "        \"  3) In this terminal, you can set:\\n\"\n",
    "        \"       set OLLAMA_HOST=http://127.0.0.1:11434   (cmd)\\n\"\n",
    "        \"       $env:OLLAMA_HOST = 'http://127.0.0.1:11434'   (PowerShell)\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacc25ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IIT BBS\\Job Resources\\Business Optima\\new-pdf-agent\\packages\\chat\\models.py:164: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  return ChatOllama(\n",
      "The 8-bit optimizer is not available on your device, only available on CUDA for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions dir: data\\sessions\n",
      "Adapter used: data\\models\\NFS_2019\\20bb948f\\adapter\n",
      "Collection:   NFS_2019\n"
     ]
    }
   ],
   "source": [
    "from packages.chat.router import mount_chat\n",
    "\n",
    "mount = mount_chat(DOC_ID)  # uses providers.yaml & profile/auto-discovery\n",
    "print(\"Sessions dir:\", mount.sessions_dir)\n",
    "print(\"Adapter used:\", mount.profile.adapter_path)\n",
    "print(\"Collection:  \", mount.profile.collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c93aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sections (first 200 chars): (outline not available)\n",
      "Abbreviations (first 200 chars): (abbreviations not available)\n"
     ]
    }
   ],
   "source": [
    "def _load_artifact_text(doc_id: str, fname: str) -> str:\n",
    "    # try a few common places; fall back empty\n",
    "    candidates = [\n",
    "        ARTIFACTS_ROOT / doc_id / fname,\n",
    "        ARTIFACTS_ROOT / doc_id / \"meta\" / fname,\n",
    "        ARTIFACTS_ROOT / doc_id / \"notes\" / fname,\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p.read_text(encoding=\"utf-8\").strip()\n",
    "    return \"\"\n",
    "\n",
    "sections_text = _load_artifact_text(DOC_ID, \"outline.txt\") or \"(outline not available)\"\n",
    "abbreviations_text = _load_artifact_text(DOC_ID, \"abbreviations.txt\") or \"(abbreviations not available)\"\n",
    "\n",
    "print(\"Sections (first 200 chars):\", sections_text[:200].replace(\"\\n\",\" \") + (\"...\" if len(sections_text)>200 else \"\"))\n",
    "print(\"Abbreviations (first 200 chars):\", abbreviations_text[:200].replace(\"\\n\",\" \") + (\"...\" if len(abbreviations_text)>200 else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe24cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the Section 3 fees?\n",
      "→ prefilter: {'ok': True, 'reason': 'ok'}\n",
      "→ decision : {\"in_scope\": true, \"intent\": \"glossary\", \"reason\": \"\", \"rewritten\": \"What are the Section 3 fees?\"}\n",
      "\n",
      "Q: Compute the reimbursement using the table in section N 25 8 28 3 for code 12345.\n",
      "→ prefilter: {'ok': True, 'reason': 'ok'}\n",
      "→ decision : {\"in_scope\": true, \"intent\": \"table\", \"reason\": \"The reimbursement can be computed using the table in section N 25 8 28 3 for code 12345.\", \"rewritten\": \"Compute the reimbursement using the table in section N 25 8 28 3 for code 12345.\"}\n",
      "\n",
      "Q: Who won the Premier League in 2021?\n",
      "→ prefilter: {'ok': True, 'reason': 'ok'}\n",
      "→ decision : {\"in_scope\": false, \"intent\": \"other\", \"reason\": \"Premier League winner not covered in this document\", \"rewritten\": \"\"}\n",
      "\n",
      "Q: Define 'conversion factor' used in this document.\n",
      "→ prefilter: {'ok': True, 'reason': 'ok'}\n",
      "→ decision : {\"in_scope\": true, \"intent\": \"glossary\", \"reason\": \"\", \"rewritten\": \"Define 'conversion factor' used in this document.\"}\n",
      "\n",
      "Q: What's the PDF version and publication year?\n",
      "→ prefilter: {'ok': True, 'reason': 'ok'}\n",
      "→ decision : {\"in_scope\": true, \"intent\": \"meta\", \"reason\": \"\", \"rewritten\": \"What is the PDF version and publication year?\"}\n"
     ]
    }
   ],
   "source": [
    "from packages.chat.guardrails import route_scope\n",
    "\n",
    "tests_guard = [\n",
    "    \"What are the Section 3 fees?\",\n",
    "    \"Compute the reimbursement using the table in section N 25 8 28 3 for code 12345.\",\n",
    "    \"Who won the Premier League in 2021?\",\n",
    "    \"Define 'conversion factor' used in this document.\",\n",
    "    \"What's the PDF version and publication year?\",\n",
    "]\n",
    "\n",
    "def try_guard(q: str):\n",
    "    return route_scope(\n",
    "        mount.llm_intro,\n",
    "        doc_id=DOC_ID,\n",
    "        sections_text=sections_text,\n",
    "        abbreviations_text=abbreviations_text,\n",
    "        user_query=q,\n",
    "    )\n",
    "\n",
    "import json\n",
    "for q in tests_guard:\n",
    "    r = try_guard(q)\n",
    "    print(\"\\nQ:\", q)\n",
    "    print(\"→ prefilter:\", r[\"prefilter\"])\n",
    "    print(\"→ decision :\", json.dumps(r[\"decision\"], ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4eae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are Section 3 fees and also define conversion factor.\n",
      "→ ['q1: What are Section 3 fees?', 'q2: Define conversion factor.'] | notes: \n",
      "\n",
      "Q: Compute reimbursement from section N 25 8 28 3 for code 12345; also, what’s the PDF version?\n",
      "→ ['q1: What is the reimbursement for section N 25 8 28 3?', 'q2: What is the PDF version?'] | notes: \n",
      "\n",
      "Q: Only this: conversion factor definition.\n",
      "→ ['q1: What is the conversion factor definition?'] | notes: \n",
      "\n",
      "Q: Three things: A) Section 3, B) formula for X, C) any glossary of N 25 8 28 3?\n",
      "→ ['q1: What section is being referred to?', 'q2: What is the formula for X?', 'q3: Can you provide a glossary of N 25 8 28 3?'] | notes: \n",
      "\n",
      "Q: What are the fees; and the conversion factor; and publication year 2019?\n",
      "→ ['q1: What are the fees?', 'q2: What is the conversion factor?', 'q3: What was the publication year in 2019?'] | notes: \n"
     ]
    }
   ],
   "source": [
    "from packages.chat.splitter import split_and_clean\n",
    "\n",
    "tests_splitter = [\n",
    "    \"What are Section 3 fees and also define conversion factor.\",\n",
    "    \"Compute reimbursement from section N 25 8 28 3 for code 12345; also, what’s the PDF version?\",\n",
    "    \"Only this: conversion factor definition.\",\n",
    "    \"Three things: A) Section 3, B) formula for X, C) any glossary of N 25 8 28 3?\",\n",
    "    \"What are the fees; and the conversion factor; and publication year 2019?\",\n",
    "]\n",
    "\n",
    "def pretty_plan(plan):\n",
    "    return [f\"{q.id}: {q.text}\" for q in plan.questions], plan.notes\n",
    "\n",
    "for q in tests_splitter:\n",
    "    plan = split_and_clean(mount.llm_splitter, q)\n",
    "    items, notes = pretty_plan(plan)\n",
    "    print(\"\\nQ:\", q)\n",
    "    print(\"→\", items, \"| notes:\", notes or \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a0b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity assertions passed\n"
     ]
    }
   ],
   "source": [
    "# a simple out-of-scope check and simple split size check\n",
    "g1 = try_guard(\"Who won the Premier League in 2021?\")\n",
    "assert g1[\"decision\"] and (g1[\"decision\"][\"in_scope\"] is False), \"Sports Q should be out-of-scope\"\n",
    "\n",
    "plan = split_and_clean(mount.llm_splitter, \"A) Section 3 fees; B) conversion factor; C) PDF version?\")\n",
    "assert 1 <= len(plan.questions) <= int(cfg.get(\"chat.splitter.max_questions\", 6)), \"Split count violates config bound\"\n",
    "\n",
    "print(\"Sanity assertions passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77fbd816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are Section 3 fees and define conversion factor.\n",
      "decision: {'in_scope': True, 'intent': 'glossary', 'reason': '', 'rewritten': 'define conversion factor for Section 3 fees'}\n",
      "split: ['q1:What is the conversion factor for Section 3 fees?', 'q2:How to calculate Section 3 fees conversion factor?'] | notes: \n",
      "\n",
      "Q: Who won the Premier League in 2021?\n",
      "decision: {'in_scope': False, 'intent': 'other', 'reason': 'Premier League winner not covered in this document', 'rewritten': 'Who won the Premier League?'}\n",
      "Out-of-scope or blocked; stop early (no retriever / no tools).\n",
      "\n",
      "Q: Compute reimbursement for code 12345 from N 25 8 28 3 and tell the PDF version.\n",
      "decision: {'in_scope': True, 'intent': 'meta', 'reason': 'The document provides information about the PDF version.', 'rewritten': 'What is the PDF version of this document?'}\n",
      "split: ['q1:Is there a PDF version of this document?', 'q2:Where can I find the PDF version of this document?'] | notes: \n"
     ]
    }
   ],
   "source": [
    "def guard_then_split(user_query: str):\n",
    "    # 1) guard\n",
    "    g = route_scope(\n",
    "        mount.llm_intro,\n",
    "        doc_id=DOC_ID,\n",
    "        sections_text=sections_text,\n",
    "        abbreviations_text=abbreviations_text,\n",
    "        user_query=user_query,\n",
    "    )\n",
    "    dec = g[\"decision\"]\n",
    "    if not dec or not dec.get(\"in_scope\", False):\n",
    "        return {\n",
    "            \"prefilter\": g[\"prefilter\"],\n",
    "            \"decision\": dec,\n",
    "            \"split\": None,\n",
    "            \"note\": \"Out-of-scope or blocked; stop early (no retriever / no tools).\"\n",
    "        }\n",
    "\n",
    "    # 2) choose the text we pass downstream (rewritten if present)\n",
    "    rewritten = (dec.get(\"rewritten\") or user_query).strip()\n",
    "\n",
    "    # 3) split (the cleaner is baked into split_and_clean)\n",
    "    plan = split_and_clean(mount.llm_splitter, rewritten)\n",
    "\n",
    "    return {\"prefilter\": g[\"prefilter\"], \"decision\": dec, \"split\": plan}\n",
    "\n",
    "# demo\n",
    "pipe_tests = [\n",
    "    \"What are Section 3 fees and define conversion factor.\",\n",
    "    \"Who won the Premier League in 2021?\",\n",
    "    \"Compute reimbursement for code 12345 from N 25 8 28 3 and tell the PDF version.\",\n",
    "]\n",
    "\n",
    "for q in pipe_tests:\n",
    "    out = guard_then_split(q)\n",
    "    print(\"\\nQ:\", q)\n",
    "    print(\"decision:\", out[\"decision\"])\n",
    "    if out[\"split\"]:\n",
    "        print(\"split:\", [f\"{s.id}:{s.text}\" for s in out[\"split\"].questions], \"| notes:\", out[\"split\"].notes)\n",
    "    else:\n",
    "        print(out[\"note\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0d9336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro   : Ready.\n",
      "splitter: I don't have enough information to accurately determine whether you're referring to a specific context or topic related to \"Split\" (A and B)\n",
      "output  : I couldn't find any information on \"Ready -> OK\". Could you provide more context or clarify what this term refers to? I'll do my best to hel\n"
     ]
    }
   ],
   "source": [
    "def safe_ping(llm, prompt):\n",
    "    try:\n",
    "        return llm.invoke(prompt).content[:140]\n",
    "    except Exception as e:\n",
    "        return f\"[unavailable: {type(e).__name__}]\"\n",
    "\n",
    "print(\"intro   :\", safe_ping(mount.llm_intro, \"Say 'ready'.\"))\n",
    "print(\"splitter:\", safe_ping(mount.llm_splitter, \"Split: A and B?\"))\n",
    "print(\"output  :\", safe_ping(mount.llm_output, \"Summarize 'ready -> ok'.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c84b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-agent-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
