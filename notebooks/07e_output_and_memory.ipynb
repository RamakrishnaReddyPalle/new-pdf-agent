{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc1274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\IIT BBS\\Job Resources\\Business Optima\\new-pdf-agent\n"
     ]
    }
   ],
   "source": [
    "# --- 0) bootstrap ---\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT / \"pyproject.toml\").exists() and ROOT != ROOT.parent:\n",
    "    ROOT = ROOT.parent\n",
    "os.chdir(ROOT)\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "print(\"Project root:\", ROOT)\n",
    "\n",
    "DOC_ID = \"NFS_2019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c707fabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions dir: data\\sessions\n",
      "Adapter used: data\\models\\NFS_2019\\20bb948f\\adapter\n",
      "Collection:   NFS_2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IIT BBS\\Job Resources\\Business Optima\\new-pdf-agent\\packages\\chat\\models.py:164: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  return ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "# --- 1) mount (reuses your 7.1 mount) ---\n",
    "from packages.chat.router import mount_chat\n",
    "mount = mount_chat(DOC_ID)\n",
    "print(\"Sessions dir:\", mount.sessions_dir)\n",
    "print(\"Adapter used:\", mount.profile.adapter_path)\n",
    "print(\"Collection:  \", mount.profile.collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab5f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session file: data\\sessions\\NFS_2019_82aebab93556.json\n"
     ]
    }
   ],
   "source": [
    "# --- 2) sanity ping + memory store init ---\n",
    "from packages.chat.memory import SessionStore, SummaryBuffer\n",
    "store = SessionStore(mount.sessions_dir, doc_id=DOC_ID).load_or_create()\n",
    "buf = SummaryBuffer(store, llm=mount.llm_output)\n",
    "print(\"Session file:\", store.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c854092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) stream helper for run_turn ---\n",
    "import asyncio\n",
    "from packages.chat.router import run_turn\n",
    "\n",
    "async def chat_once(session_id: str, text: str):\n",
    "    events = []\n",
    "    async for ev in run_turn(DOC_ID, session_id, text):\n",
    "        t = ev.get(\"type\")\n",
    "        if t in (\"final_token\",):\n",
    "            # print streaming tokens briefly\n",
    "            print(ev[\"data\"], end=\"\", flush=True)\n",
    "        elif t == \"final\":\n",
    "            print(\"\\n\\n— FINAL —\")\n",
    "            print(ev[\"data\"][\"text\"][:600])\n",
    "        else:\n",
    "            # collect debug events\n",
    "            events.append(ev)\n",
    "    return events\n",
    "\n",
    "session_id = \"sess7eA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bfc42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> OOS demo\n",
      "There is no information available to provide a response on the topic. The requested information about the Premier League winner is out of scope for this document. \n",
      "\n",
      "If you're looking for information on football teams, league standings, or player statistics, consider asking about those topics instead. You could also ask about the history of the Premier League or its current season.\n",
      "\n",
      "— FINAL —\n",
      "There is no information available to provide a response on the topic. The requested information about the Premier League winner is out of scope for this document. \n",
      "\n",
      "If you're looking for information on football teams, league standings, or player statistics, consider asking about those topics instead. You could also ask about the history of the Premier League or its current season.\n",
      "\n",
      "Guard + Misc events: ['guard']\n"
     ]
    }
   ],
   "source": [
    "# --- 4) OOS handoff demo ---\n",
    "print(\">>> OOS demo\")\n",
    "oos_events = await chat_once(session_id, \"Who won the Premier League in 2021?\")\n",
    "print(\"\\nGuard + Misc events:\", [e[\"type\"] for e in oos_events])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf4d149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> In-scope demo\n",
      "The conversion factor for Section 3 fees can be found in the fee schedule. According to the provided information, the following codes are subject to this conversion factor: [id]NFS_2019-11015[/id]. The specific code mentioned is \"The following codes are subject to the conversion factor from the section listed.\" (CORE_ANSWERS_JSON[1][\"answer\"]).\n",
      "\n",
      "— FINAL —\n",
      "The conversion factor for Section 3 fees can be found in the fee schedule. According to the provided information, the following codes are subject to this conversion factor: [id]NFS_2019-11015[/id]. The specific code mentioned is \"The following codes are subject to the conversion factor from the section listed.\" (CORE_ANSWERS_JSON[1][\"answer\"]).\n",
      "\n",
      "Guard + Misc events: ['guard', 'split', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_final', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_token', 'core_final']\n"
     ]
    }
   ],
   "source": [
    "# --- 5) In-scope demo (split->core->stitch) ---\n",
    "print(\"\\n>>> In-scope demo\")\n",
    "ins_events = await chat_once(session_id, \"What are Section 3 fees and define conversion factor?\")\n",
    "print(\"\\nGuard + Misc events:\", [e[\"type\"] for e in ins_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbf0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      " \n",
      "\n",
      "Tail turns: []\n"
     ]
    }
   ],
   "source": [
    "# --- 6) Memory summary check ---\n",
    "from pathlib import Path\n",
    "print(\"\\nSummary:\\n\", store.summary_text())\n",
    "print(\"\\nTail turns:\", [(t.role, t.content[:50]) for t in store.state.turns[-6:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea20115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> New session B: memory should be cold\n",
      "To define a conversion factor, we can use the provided JSON schema and create an object that conforms to it.\n",
      "\n",
      "Here's an example of how to do this:\n",
      "```\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"Citation\": {\n",
      "      ...\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"conversion_factor\": {\n",
      "      \"description\": \"Conversion factor value\",\n",
      "      \"title\": \"Conversion Factor\",\n",
      "      \"type\": \"number\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\"answer\"]\n",
      "}\n",
      "```\n",
      "This object defines a new property called `conversion_factor` with a type of `number`, which represents the conversion factor value.\n",
      "\n",
      "To create an instance of this schema, we can use the provided top snippets as context. Since there is no direct mention of a conversion factor in the text, we'll have to make an educated guess based on the available information.\n",
      "\n",
      "After analyzing the text, it appears that the conversion factor might be related to the \"B+\" grade mentioned in snippet #NFS_2019-11071. However, without more context or information about how the conversion factor is calculated, we can't provide a precise value.\n",
      "\n",
      "Therefore, our best guess would be to use the score from snippet #NFS_2019-11071 as a rough estimate of the conversion factor:\n",
      "```\n",
      "{\n",
      "  \"answer\": \"\",\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"id\": \"NFS_2019-11071\",\n",
      "      \"text\": \"B+\"\n",
      "    }\n",
      "  ],\n",
      "  \"conversion_factor\": 0.6659789564156384\n",
      "}\n",
      "```\n",
      "Please note that this is a rough estimate and should be taken with caution.\n",
      "\n",
      "Snippet ids used: #NFS_2019-11071\n",
      "\n",
      "— FINAL —\n",
      "To define a conversion factor, we can use the provided JSON schema and create an object that conforms to it.\n",
      "\n",
      "Here's an example of how to do this:\n",
      "```\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"Citation\": {\n",
      "      ...\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"conversion_factor\": {\n",
      "      \"description\": \"Conversion factor value\",\n",
      "      \"title\": \"Conversion Factor\",\n",
      "      \"type\": \"number\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\"answer\"]\n",
      "}\n",
      "```\n",
      "This object defines a new property called `conversion_factor` with a type of `number`, which represents the conversion factor value.\n",
      "\n",
      "To create an instance of this schema, we can use the provided top s\n",
      "\n",
      "Summary (B): \n"
     ]
    }
   ],
   "source": [
    "# --- 7) New session to verify isolation ---\n",
    "print(\"\\n>>> New session B: memory should be cold\")\n",
    "session_id_b = \"sess7eB\"\n",
    "_ = await chat_once(session_id_b, \"Define conversion factor.\")\n",
    "print(\"\\nSummary (B):\", SessionStore(mount.sessions_dir, DOC_ID, session_id_b).load_or_create().summary_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed289f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. id=NFS_2019-11219 score=0.685 heading=FEE SCHEDULE > CONVERSION FACTORS\n",
      "   text: Description Value\n",
      " 2. id=NFS_2019-11090 score=0.680 heading=FEE SCHEDULE > CONVERSION FACTORS\n",
      "   text: Description\n",
      " 3. id=NFS_2019-11851 score=0.677 heading=FEE SCHEDULE > CONVERSION FACTORS\n",
      "   text: be calculated as follows:\n",
      " 4. id=NFS_2019-11040 score=0.676 heading=FEE SCHEDULE > CONVERSION FACTORS\n",
      "   text: Code Description\n",
      " 5. id=NFS_2019-11242 score=0.672 heading=FEE SCHEDULE > CONVERSION FACTORS\n",
      "   text: R\n",
      " 6. id=NFS_2019-11243 score=0.672 heading=FEE SCHEDULE > CONVERSION FACTORS\n",
      "   text: R\n"
     ]
    }
   ],
   "source": [
    "# 1) Sanity: retriever hit sample (to see snippets are short/weak today)\n",
    "hits = mount.retriever.search(\"Define conversion factor.\")\n",
    "for i, h in enumerate(hits[:6], 1):\n",
    "    m = h.get(\"metadata\", {})\n",
    "    print(f\"{i:>2}. id={h['id']} score={h['score']:.3f} heading={m.get('heading_path')}\")\n",
    "    print(\"   text:\", (h[\"text\"][:120] + \"…\") if len(h[\"text\"])>120 else h[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b2aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER:\n",
      " The Section 3 fees are not explicitly stated in the provided context snippets.\n",
      "CITATIONS: ['NFS_2019-h-207']\n"
     ]
    }
   ],
   "source": [
    "# 2) Core RAG non-stream (check that there's no schema/prose leakage anymore)\n",
    "from packages.chat.core_rag import CoreRAG\n",
    "core = CoreRAG(mount.retriever, mount.llm_core)\n",
    "\n",
    "q = \"What are the Section 3 fees?\"\n",
    "ans = await core.answer_one(q)\n",
    "print(\"ANSWER:\\n\", ans.answer)\n",
    "print(\"CITATIONS:\", [c.id for c in ans.citations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8759ed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"a ratio or factor used to convert from one unit of measurement to another\",\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"id\": \"NFS_2019-11015\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"NFS_2019-11851\"\n",
      "    }\n",
      "  ],\n",
      "  \"notes\n",
      "\n",
      "— FINAL —\n",
      "ANSWER: a ratio or factor used to convert from one unit of measurement to another\n",
      "CITATIONS: ['NFS_2019-11015', 'NFS_2019-11851']\n"
     ]
    }
   ],
   "source": [
    "# 3) Core RAG stream (tokens should be JSON-looking or clean text; no schema dump)\n",
    "buf = \"\"\n",
    "async for ev in core.astream_one(\"Define 'conversion factor' used in this document.\"):\n",
    "    if ev[\"type\"] == \"core_token\":\n",
    "        t = ev[\"data\"]\n",
    "        if len(buf) < 200:  # print brief prefix\n",
    "            print(t, end=\"\")\n",
    "        buf += t\n",
    "    elif ev[\"type\"] == \"core_final\":\n",
    "        fin = ev[\"data\"]\n",
    "        print(\"\\n\\n— FINAL —\")\n",
    "        print(\"ANSWER:\", fin.answer)\n",
    "        print(\"CITATIONS:\", [c.id for c in fin.citations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c25164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STITCHED:\n",
      " I can help with questions about Section 3 fees and conversion factors. \n",
      "\n",
      "For Section 3 fees, please refer to the applicable fee schedule.\n",
      "\n",
      "For conversion factors, check the Conversion Factors section for definitions.\n"
     ]
    }
   ],
   "source": [
    "# 4) Stitcher (in-scope): ensure no internal names show up\n",
    "from packages.chat.output_llm import astitch_text_stream\n",
    "\n",
    "fake_answers = [\n",
    "    {\"answer\": \"Section 3 fees are listed under the applicable fee schedule.\", \"citations\":[{\"id\":\"NFS_2019-11118\"}], \"notes\":\"\"},\n",
    "    {\"answer\": \"The conversion factor is defined in the Conversion Factors section.\", \"citations\":[{\"id\":\"NFS_2019-11040\"}], \"notes\":\"\"}\n",
    "]\n",
    "\n",
    "buf = \"\"\n",
    "async for tok in astitch_text_stream(mount.llm_output, fake_answers, memory_summary=\"(none)\"):\n",
    "    buf += tok\n",
    "print(\"STITCHED:\\n\", buf)\n",
    "assert \"CORE_ANSWERS\" not in buf and \"schema\" not in buf.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0244fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS STITCHED:\n",
      " I'm unable to provide information on football results as it is out of scope. If you're looking for sports statistics, I can help with general information or suggest follow-up questions such as \"What type of statistics are you interested in?\" or \"Are you looking for historical data or current trends?\".\n"
     ]
    }
   ],
   "source": [
    "# 5) Stitcher (OOS): friendly handoff with reason; still clean prose\n",
    "buf = \"\"\n",
    "async for tok in astitch_text_stream(mount.llm_output, [], memory_summary=\"(none)\", oos_reason=\"This document does not cover football results.\"):\n",
    "    buf += tok\n",
    "print(\"OOS STITCHED:\\n\", buf)\n",
    "assert \"CORE_ANSWERS\" not in buf and \"schema\" not in buf.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a77a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session file: data\\sessions\\NFS_2019_75acb9189433.json\n",
      "\n",
      "SUMMARY:\n",
      " The user requested information on Section 3 fees, a conversion factor, and the PDF publication year. The assistant agreed to provide this information.\n",
      "\n",
      "TAIL TURNS: ['Hi, I need the Section 3 fees and the conversion factor.', 'Let me check the relevant sections.', 'Also, what is the PDF publication year?', \"I'll include that too.\"]\n"
     ]
    }
   ],
   "source": [
    "# 6) Memory summary demo (yours looked empty because thresholds weren't met)\n",
    "from packages.chat.memory import SessionStore, SummaryBuffer\n",
    "\n",
    "sess_dir = mount.sessions_dir\n",
    "store = SessionStore(sess_dir, DOC_ID).load_or_create()   # creates a fresh session\n",
    "sid = store.session_id\n",
    "print(\"Session file:\", store.path)\n",
    "\n",
    "# Append some turns so there's something to summarize\n",
    "store.append(\"user\", \"Hi, I need the Section 3 fees and the conversion factor.\")\n",
    "store.append(\"assistant\", \"Let me check the relevant sections.\")\n",
    "store.append(\"user\", \"Also, what is the PDF publication year?\")\n",
    "store.append(\"assistant\", \"I'll include that too.\")\n",
    "\n",
    "# Force summarization now (no threshold wait)\n",
    "sb = SummaryBuffer(store, mount.llm_output, summarize_every=2, char_budget=1000)\n",
    "summary = await sb.asummarize_now()\n",
    "\n",
    "print(\"\\nSUMMARY:\\n\", summary)\n",
    "print(\"\\nTAIL TURNS:\", [t.content for t in store.last_n(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa262c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> OOS\n",
      "I can provide information on Section 3 fees and the PDF publication year. However, I couldn't find any information on a conversion factor related to this topic.\n",
      "\n",
      "For Section 3 fees, please refer to [id] for more details. The PDF publication year is not available in my current database.\n",
      "\n",
      "To further assist you, I can provide information on Premier League winners or offer general guidance on finding the required conversion factor.\n",
      "\n",
      ">>> In-scope\n",
      "Unfortunately, I couldn't find information on a conversion factor. However, you can refer to [NFS_2019-11219] for more details on Section 3 fees. The PDF publication year for your specific topic is not available in my database.\n"
     ]
    }
   ],
   "source": [
    "# 7) End-to-end: OOS + In-scope via your router.run_turn (final tokens only)\n",
    "from packages.chat.router import run_turn\n",
    "\n",
    "async def run_and_collect(q: str):\n",
    "    buf = \"\"\n",
    "    async for ev in run_turn(DOC_ID, session_id=sid, user_query=q):\n",
    "        if ev.get(\"type\") == \"final_token\":\n",
    "            buf += ev[\"data\"]\n",
    "    return buf\n",
    "\n",
    "print(\">>> OOS\")\n",
    "print(await run_and_collect(\"Who won the Premier League in 2021?\"))\n",
    "\n",
    "print(\"\\n>>> In-scope\")\n",
    "print(await run_and_collect(\"Define conversion factor used in this document.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-agent-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
