{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6dd2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\IIT BBS\\Job Resources\\Business Optima\\new-pdf-agent\n"
     ]
    }
   ],
   "source": [
    "# 0) bootstrap\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT / \"pyproject.toml\").exists() and ROOT != ROOT.parent:\n",
    "    ROOT = ROOT.parent\n",
    "os.chdir(ROOT)\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "print(\"Project root:\", ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7f947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model ID: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "Base model dir: models\\llm\\TinyLlama-1.1B-Chat-v1.0\n"
     ]
    }
   ],
   "source": [
    "# 1) load config & doc id\n",
    "from packages.core_config.config import load_yaml\n",
    "\n",
    "cfg = load_yaml(\"configs/providers.yaml\", \"configs/pipelines/generic_legal.yaml\")\n",
    "doc_id = \"NFS_2019\"\n",
    "\n",
    "ft = cfg.get(\"finetune\", {})\n",
    "base_id   = str(ft.get(\"base_model_id\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"))\n",
    "base_dir  = Path(ft.get(\"base_model_local_dir\", \"models/llm/TinyLlama-1.1B-Chat-v1.0\"))\n",
    "dl_conf   = ft.get(\"download\", {})\n",
    "datasets_root = Path(ft.get(\"datasets_root\", \"data/datasets\"))\n",
    "output_root   = Path(ft.get(\"output_root\", \"data/models\"))\n",
    "\n",
    "print(\"Base model ID:\", base_id)\n",
    "print(\"Base model dir:\", base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f176be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) optional: ensure download (runs only if folder missing or empty)\n",
    "# from scripts.download_hf_model import ensure_downloaded, HFDownloadSpec\n",
    "\n",
    "# if dl_conf.get(\"allow\", True):\n",
    "#     ensure_downloaded(HFDownloadSpec(\n",
    "#         repo_id=base_id,\n",
    "#         local_dir=base_dir,\n",
    "#         revision=dl_conf.get(\"revision\"),\n",
    "#         ignore_patterns=dl_conf.get(\"ignore_patterns\"),\n",
    "#     ))\n",
    "#     print(\"âœ“ Model ready at:\", base_dir.resolve())\n",
    "# else:\n",
    "#     print(\"Download disabled; expecting model already present at:\", base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a557c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d2ea2d3cee4cdca0228a9d76c47b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc9155219894e47aca5a4acc93de780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 8-bit optimizer is not available on your device, only available on CUDA for now.\n",
      "d:\\IIT BBS\\Job Resources\\Business Optima\\new-pdf-agent\\packages\\finetune\\submit_job.py:271: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "d:\\Anaconda\\envs\\pdf-agent-2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 24:22, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.844100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.286400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.274400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.773400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.742300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.530100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.329800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.685400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'c0e8976c', 'doc_id': 'NFS_2019', 'created_at': 1758184431, 'status': 'COMPLETED', 'backend': 'local_peft', 'enable_training': True, 'base_model': 'models\\\\llm\\\\TinyLlama-1.1B-Chat-v1.0', 'run_dir': 'data\\\\models\\\\NFS_2019\\\\20bb948f', 'artifacts': {'adapter_path': 'data\\\\models\\\\NFS_2019\\\\20bb948f\\\\adapter'}, 'config': {'backend': 'local_peft', 'enable_training': True, 'output_root': 'data\\\\models', 'datasets_root': 'data\\\\datasets', 'doc_id': 'NFS_2019', 'base_model_id': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', 'base_model_local_dir': 'models\\\\llm\\\\TinyLlama-1.1B-Chat-v1.0', 'lora_r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['q_proj', 'v_proj'], 'learning_rate': 0.0002, 'weight_decay': 0.0, 'max_steps': 20, 'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 4, 'bf16': False, 'fp16': False, 'seed': 42}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'c0e8976c',\n",
       " 'doc_id': 'NFS_2019',\n",
       " 'created_at': 1758184431,\n",
       " 'status': 'COMPLETED',\n",
       " 'backend': 'local_peft',\n",
       " 'enable_training': True,\n",
       " 'base_model': 'models\\\\llm\\\\TinyLlama-1.1B-Chat-v1.0',\n",
       " 'run_dir': 'data\\\\models\\\\NFS_2019\\\\20bb948f',\n",
       " 'artifacts': {'adapter_path': 'data\\\\models\\\\NFS_2019\\\\20bb948f\\\\adapter'},\n",
       " 'config': {'backend': 'local_peft',\n",
       "  'enable_training': True,\n",
       "  'output_root': 'data\\\\models',\n",
       "  'datasets_root': 'data\\\\datasets',\n",
       "  'doc_id': 'NFS_2019',\n",
       "  'base_model_id': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
       "  'base_model_local_dir': 'models\\\\llm\\\\TinyLlama-1.1B-Chat-v1.0',\n",
       "  'lora_r': 8,\n",
       "  'lora_alpha': 16,\n",
       "  'lora_dropout': 0.05,\n",
       "  'target_modules': ['q_proj', 'v_proj'],\n",
       "  'learning_rate': 0.0002,\n",
       "  'weight_decay': 0.0,\n",
       "  'max_steps': 20,\n",
       "  'per_device_train_batch_size': 1,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'bf16': False,\n",
       "  'fp16': False,\n",
       "  'seed': 42}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) submit stub job (no heavy training)\n",
    "from packages.finetune.submit_job import submit_job, FinetuneConfig\n",
    "from packages.finetune.track_status import read_status\n",
    "from packages.finetune.register_model import register_model\n",
    "\n",
    "cfg_ft = FinetuneConfig(\n",
    "    backend=str(ft.get(\"backend\", \"local_peft\")),\n",
    "    enable_training=bool(ft.get(\"enable_training\", True)),\n",
    "    output_root=str(output_root),\n",
    "    datasets_root=str(datasets_root),\n",
    "    doc_id=doc_id,\n",
    "    # model resolution: let code prefer local_dir if exists\n",
    "    base_model_id=base_id,\n",
    "    base_model_local_dir=str(base_dir),\n",
    "    # LoRA params (passed through; used only if enable_training: true)\n",
    "    lora_r=int(ft.get(\"lora\", {}).get(\"r\", 8)),\n",
    "    lora_alpha=int(ft.get(\"lora\", {}).get(\"alpha\", 16)),\n",
    "    lora_dropout=float(ft.get(\"lora\", {}).get(\"dropout\", 0.05)),\n",
    "    target_modules=tuple(ft.get(\"lora\", {}).get(\"target_modules\", [\"q_proj\",\"v_proj\"])),\n",
    "    # Train params (used only if enable_training: true)\n",
    "    learning_rate=float(ft.get(\"train\", {}).get(\"learning_rate\", 2e-4)),\n",
    "    weight_decay=float(ft.get(\"train\", {}).get(\"weight_decay\", 0.0)),\n",
    "    max_steps=int(ft.get(\"train\", {}).get(\"max_steps\", 20)),\n",
    "    per_device_train_batch_size=int(ft.get(\"train\", {}).get(\"per_device_train_batch_size\", 1)),\n",
    "    gradient_accumulation_steps=int(ft.get(\"train\", {}).get(\"gradient_accumulation_steps\", 4)),\n",
    "    bf16=bool(ft.get(\"train\", {}).get(\"bf16\", False)),\n",
    "    fp16=bool(ft.get(\"train\", {}).get(\"fp16\", False)),\n",
    "    seed=int(ft.get(\"train\", {}).get(\"seed\", 42)),\n",
    ")\n",
    "\n",
    "job = submit_job(cfg_ft)\n",
    "print(job)\n",
    "\n",
    "state = read_status(job[\"run_dir\"])\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b25495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered: {'id': 'b0b53f84', 'doc_id': 'NFS_2019', 'profile': 'generic', 'base_model': 'models\\\\llm\\\\TinyLlama-1.1B-Chat-v1.0', 'adapter_path': 'data\\\\models\\\\NFS_2019\\\\20bb948f\\\\adapter', 'run_dir': 'data\\\\models\\\\NFS_2019\\\\20bb948f', 'created_at': 1758186420, 'extra': {}}\n"
     ]
    }
   ],
   "source": [
    "# 4) register (so the router can pick it up later)\n",
    "if ft.get(\"register\", True) and state[\"status\"] == \"COMPLETED\":\n",
    "    rec = register_model(\n",
    "        doc_id=doc_id,\n",
    "        base_model=state[\"base_model\"],\n",
    "        adapter_path=state[\"artifacts\"].get(\"adapter_path\"),\n",
    "        run_dir=job[\"run_dir\"],\n",
    "        profile=\"generic\",\n",
    "    )\n",
    "    print(\"Registered:\", rec)\n",
    "else:\n",
    "    print(\"Skipped register; status:\", state[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3e6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-agent-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
